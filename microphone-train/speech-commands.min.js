// @tensorflow/tfjs-models Copyright 2018 Google
!function(t,e){"object"==typeof exports&&"undefined"!=typeof module?e(exports,require("@tensorflow/tfjs")):"function"==typeof define&&define.amd?define(["exports","@tensorflow/tfjs"],e):e(t.SpeechCommands={},t.tf)}(this,function(t,e){"use strict";var r=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(t,e){t.__proto__=e}||function(t,e){for(var r in e)e.hasOwnProperty(r)&&(t[r]=e[r])};function n(t,e,r,n){return new(r||(r=Promise))(function(s,o){function a(t){try{l(n.next(t))}catch(t){o(t)}}function i(t){try{l(n.throw(t))}catch(t){o(t)}}function l(t){t.done?s(t.value):new r(function(e){e(t.value)}).then(a,i)}l((n=n.apply(t,e||[])).next())})}function s(t,e){var r,n,s,o,a={label:0,sent:function(){if(1&s[0])throw s[1];return s[1]},trys:[],ops:[]};return o={next:i(0),throw:i(1),return:i(2)},"function"==typeof Symbol&&(o[Symbol.iterator]=function(){return this}),o;function i(o){return function(i){return function(o){if(r)throw new TypeError("Generator is already executing.");for(;a;)try{if(r=1,n&&(s=2&o[0]?n.return:o[0]?n.throw||((s=n.return)&&s.call(n),0):n.next)&&!(s=s.call(n,o[1])).done)return s;switch(n=0,s&&(o=[2&o[0],s.value]),o[0]){case 0:case 1:s=o;break;case 4:return a.label++,{value:o[1],done:!1};case 5:a.label++,n=o[1],o=[0];continue;case 7:o=a.ops.pop(),a.trys.pop();continue;default:if(!(s=(s=a.trys).length>0&&s[s.length-1])&&(6===o[0]||2===o[0])){a=0;continue}if(3===o[0]&&(!s||o[1]>s[0]&&o[1]<s[3])){a.label=o[1];break}if(6===o[0]&&a.label<s[1]){a.label=s[1],s=o;break}if(s&&a.label<s[2]){a.label=s[2],a.ops.push(o);break}s[2]&&a.ops.pop(),a.trys.pop();continue}o=e.call(t,a)}catch(t){o=[6,t],n=0}finally{r=s=0}if(5&o[0])throw o[1];return{value:o[0]?o[1]:void 0,done:!0}}([o,i])}}}function o(t,e){var r="function"==typeof Symbol&&t[Symbol.iterator];if(!r)return t;var n,s,o=r.call(t),a=[];try{for(;(void 0===e||e-- >0)&&!(n=o.next()).done;)a.push(n.value)}catch(t){s={error:t}}finally{try{n&&!n.done&&(r=o.return)&&r.call(o)}finally{if(s)throw s.error}}return a}var a=function(){function t(t){if(this.ROTATING_BUFFER_SIZE_MULTIPLIER=2,null==t)throw new Error("Required configuration object is missing for BrowserFftFeatureExtractor constructor");if(null==t.spectrogramCallback)throw new Error("spectrogramCallback cannot be null or undefined");if(!(t.numFramesPerSpectrogram>0))throw new Error("Invalid value in numFramesPerSpectrogram: "+t.numFramesPerSpectrogram);if(t.suppressionTimeMillis<0)throw new Error("Expected suppressionTimeMillis to be >= 0, but got "+t.suppressionTimeMillis);this.suppressionTimeMillis=t.suppressionTimeMillis,this.spectrogramCallback=t.spectrogramCallback,this.numFramesPerSpectrogram=t.numFramesPerSpectrogram,this.sampleRateHz=t.sampleRateHz||44100,this.fftSize=t.fftSize||1024,this.frameDurationMillis=this.fftSize/this.sampleRateHz*1e3,this.columnTruncateLength=t.columnTruncateLength||this.fftSize;var e=t.columnBufferLength||this.fftSize,r=t.columnHopLength||this.fftSize/2;if(this.overlapFactor=r/e,!(this.overlapFactor>0))throw new Error("Invalid overlapFactor: "+this.overlapFactor+". Check your columnBufferLength and columnHopLength.");if(this.columnTruncateLength>this.fftSize)throw new Error("columnTruncateLength "+this.columnTruncateLength+" exceeds fftSize ("+this.fftSize+").");this.audioContextConstructor=window.AudioContext||window.webkitAudioContext}return t.prototype.start=function(t){return n(this,void 0,void 0,function(){var t,e,r;return s(this,function(o){switch(o.label){case 0:if(null!=this.frameIntervalTask)throw new Error("Cannot start already-started BrowserFftFeatureExtractor");return t=this,[4,function(){return n(this,void 0,void 0,function(){return s(this,function(t){switch(t.label){case 0:return[4,navigator.mediaDevices.getUserMedia({audio:!0,video:!1})];case 1:return[2,t.sent()]}})})}()];case 1:return t.stream=o.sent(),this.audioContext=new this.audioContextConstructor,this.audioContext.sampleRate!==this.sampleRateHz&&console.warn("Mismatch in sampling rate: Expected: "+this.sampleRateHz+"; Actual: "+this.audioContext.sampleRate),e=this.audioContext.createMediaStreamSource(this.stream),this.analyser=this.audioContext.createAnalyser(),this.analyser.fftSize=2*this.fftSize,this.analyser.smoothingTimeConstant=0,e.connect(this.analyser),this.freqData=new Float32Array(this.fftSize),this.rotatingBufferNumFrames=this.numFramesPerSpectrogram*this.ROTATING_BUFFER_SIZE_MULTIPLIER,r=this.columnTruncateLength*this.rotatingBufferNumFrames,this.rotatingBuffer=new Float32Array(r),this.frameCount=0,this.tracker=new i(Math.round(this.numFramesPerSpectrogram*this.overlapFactor),Math.round(this.suppressionTimeMillis/this.frameDurationMillis)),this.frameIntervalTask=setInterval(this.onAudioFrame.bind(this),this.fftSize/this.sampleRateHz*1e3),[2]}})})},t.prototype.onAudioFrame=function(){return n(this,void 0,void 0,function(){var t,r,n,o;return s(this,function(s){switch(s.label){case 0:return this.analyser.getFloatFrequencyData(this.freqData),this.freqData[0]===-1/0?(console.warn("No signal (frame #"+this.frameCount+")"),[2]):(t=this.freqData.slice(0,this.columnTruncateLength),r=this.frameCount%this.rotatingBufferNumFrames,this.rotatingBuffer.set(t,r*this.columnTruncateLength),this.frameCount++,this.tracker.tick()?(n=function(t,e,r,n){var s=e*r,o=new Float32Array(s),a=t.length,i=a/r;for(;n<0;)n+=i;for(var l=n%i*r,u=l+s,h=l;h<u;++h)o[h-l]=t[h%a];return o}(this.rotatingBuffer,this.numFramesPerSpectrogram,this.columnTruncateLength,this.frameCount-this.numFramesPerSpectrogram),o=function(t,r,n,s){void 0===s&&(s=!0);return e.tidy(function(){for(var o=t.length,a=e.buffer([o]),i=0;i<t.length;++i)a.set(t[i],i);var l,u=a.toTensor().reshape([1,r,n,1]);return s?(l=u,e.tidy(function(){var t=e.mean(l),r=e.sqrt(e.mean(e.square(e.add(l,e.neg(t)))));return e.div(e.add(l,e.neg(t)),r)})):u})}(n,this.numFramesPerSpectrogram,this.columnTruncateLength),[4,this.spectrogramCallback(o)]):[3,2]);case 1:s.sent()&&this.tracker.suppress(),o.dispose(),s.label=2;case 2:return[2]}})})},t.prototype.stop=function(){return n(this,void 0,void 0,function(){return s(this,function(t){if(null==this.frameIntervalTask)throw new Error("Cannot stop because there is no ongoing streaming activity.");return clearInterval(this.frameIntervalTask),this.frameIntervalTask=null,this.analyser.disconnect(),this.audioContext.close(),[2]})})},t.prototype.setConfig=function(t){throw new Error("setConfig() is not implemented for BrowserFftFeatureExtractor.")},t.prototype.getFeatures=function(){throw new Error("getFeatures() is not implemented for BrowserFftFeatureExtractor. Use the spectrogramCallback field of the constructor config instead.")},t}();var i=function(){function t(t,r){this.period=t,this.suppressionTime=null==r?0:r,this.counter=0,e.util.assert(this.period>0,"Expected period to be positive, but got "+this.period)}return t.prototype.tick=function(){return this.counter++,this.counter%this.period==0&&(null==this.suppressionOnset||this.counter-this.suppressionOnset>this.suppressionTime)},t.prototype.suppress=function(){this.suppressionOnset=this.counter},t}(),l="0.1.2",u=!1,h=function(){function t(r){this.MODEL_URL_PREFIX="https://storage.googleapis.com/tfjs-speech-commands-models/v"+l+"/browser_fft",this.SAMPLE_RATE_HZ=44100,this.FFT_SIZE=1024,this.DEFAULT_SUPPRESSION_TIME_MILLIS=1e3,this.transferRecognizers={},null==r&&(r=t.DEFAULT_VOCABULARY_NAME),e.util.assert(-1!==t.VALID_VOCABULARY_NAMES.indexOf(r),"Invalid vocabulary name: '"+r+"'"),this.vocabulary=r,this.parameters={sampleRateHz:this.SAMPLE_RATE_HZ,fftSize:this.FFT_SIZE,columnBufferLength:this.FFT_SIZE}}return t.prototype.startStreaming=function(t,r){return n(this,void 0,void 0,function(){var i,l,h,c,p,f=this;return s(this,function(d){switch(d.label){case 0:if(u)throw new Error("Cannot start streaming again when streaming is ongoing.");return[4,this.ensureModelLoaded()];case 1:if(d.sent(),null==r&&(r={}),i=null==r.probabilityThreshold?0:r.probabilityThreshold,e.util.assert(i>=0&&i<=1,"Invalid probabilityThreshold value: "+i),l=null!=r.invokeCallbackOnNoiseAndUnknown&&r.invokeCallbackOnNoiseAndUnknown,r.suppressionTimeMillis<0)throw new Error("suppressionTimeMillis is expected to be >= 0, but got "+r.suppressionTimeMillis);return h=null==r.overlapFactor?.5:r.overlapFactor,e.util.assert(h>=0&&h<1,"Expected overlapFactor to be >= 0 and < 1, but got "+h),this.parameters.columnHopLength=Math.round(this.FFT_SIZE*(1-h)),c=function(a){return n(f,void 0,void 0,function(){var n,u,h,c,p,f,d,m,g=this;return s(this,function(s){switch(s.label){case 0:return[4,(n=e.tidy(function(){return g.model.predict(a)})).data()];case 1:return u=s.sent(),[4,(h=n.argMax(-1)).data()];case 2:return c=s.sent()[0],p=Math.max.apply(Math,function(){for(var t=[],e=0;e<arguments.length;e++)t=t.concat(o(arguments[e]));return t}(u)),e.dispose([n,h]),p<i?[2,!1]:[3,3];case 3:return f=void 0,r.includeSpectrogram?(d={},[4,a.data()]):[3,5];case 4:d.data=s.sent(),d.frameSize=this.nonBatchInputShape[1],f=d,s.label=5;case 5:return m=!0,l||"_background_noise_"!==this.words[c]&&"_unknown_"!==this.words[c]||(m=!1),m&&t({scores:u,spectrogram:f}),[2,m]}})})},p=null==r.suppressionTimeMillis?this.DEFAULT_SUPPRESSION_TIME_MILLIS:r.suppressionTimeMillis,this.audioDataExtractor=new a({sampleRateHz:this.parameters.sampleRateHz,columnBufferLength:this.parameters.columnBufferLength,columnHopLength:this.parameters.columnHopLength,numFramesPerSpectrogram:this.nonBatchInputShape[0],columnTruncateLength:this.nonBatchInputShape[1],suppressionTimeMillis:p,spectrogramCallback:c}),[4,this.audioDataExtractor.start()];case 2:return d.sent(),u=!0,[2]}})})},t.prototype.ensureModelLoaded=function(){return n(this,void 0,void 0,function(){var t,r,n,o,a=this;return s(this,function(s){switch(s.label){case 0:return null!=this.model?[2]:[4,this.ensureMetadataLoaded()];case 1:return s.sent(),[4,e.loadLayersModel(this.MODEL_URL_PREFIX+"/"+this.vocabulary+"/model.json")];case 2:if(1!==(t=s.sent()).inputs.length)throw new Error("Expected model to have 1 input, but got a model with "+t.inputs.length+" inputs");if(4!==t.inputs[0].shape.length)throw new Error("Expected model to have an input shape of rank 4, but got an input shape of rank "+t.inputs[0].shape.length);if(1!==t.inputs[0].shape[3])throw new Error("Expected model to have an input shape with 1 as the last dimension, but got input shape"+JSON.stringify(t.inputs[0].shape[3])+"}");if(2!==(r=t.outputShape).length)throw new Error("Expected loaded model to have an output shape of rank 2,but received shape "+JSON.stringify(r));if(r[1]!==this.words.length)throw new Error("Mismatch between the last dimension of model's output shape ("+r[1]+") and number of words ("+this.words.length+").");return this.model=t,this.freezeModel(),this.nonBatchInputShape=t.inputs[0].shape.slice(1),this.elementsPerExample=1,t.inputs[0].shape.slice(1).forEach(function(t){return a.elementsPerExample*=t}),this.warmUpModel(),n=this.parameters.columnBufferLength/this.parameters.sampleRateHz*1e3,o=t.inputs[0].shape[1],this.parameters.spectrogramDurationMillis=o*n,[2]}})})},t.prototype.warmUpModel=function(){var t=this;e.tidy(function(){for(var r=e.zeros([1].concat(t.nonBatchInputShape)),n=0;n<3;++n)t.model.predict(r)})},t.prototype.ensureMetadataLoaded=function(){return n(this,void 0,void 0,function(){var t;return s(this,function(e){switch(e.label){case 0:return null!=this.words?[2]:[4,function(t){return n(this,void 0,void 0,function(){return s(this,function(e){switch(e.label){case 0:return[4,fetch(t)];case 1:return[4,e.sent().json()];case 2:return[2,e.sent()]}})})}(this.MODEL_URL_PREFIX+"/"+this.vocabulary+"/metadata.json")];case 1:return t=e.sent(),this.words=t.words,[2]}})})},t.prototype.stopStreaming=function(){return n(this,void 0,void 0,function(){return s(this,function(t){switch(t.label){case 0:if(!u)throw new Error("Cannot stop streaming when streaming is not ongoing.");return[4,this.audioDataExtractor.stop()];case 1:return t.sent(),u=!1,[2]}})})},t.prototype.isStreaming=function(){return u},t.prototype.wordLabels=function(){return this.words},t.prototype.params=function(){return this.parameters},t.prototype.modelInputShape=function(){if(null==this.model)throw new Error("Model has not been loaded yet. Load model by calling ensureModelLoaded(), recognizer(), or startStreaming().");return this.model.inputs[0].shape},t.prototype.recognize=function(t){return n(this,void 0,void 0,function(){var r,n,o,a,i,l,u;return s(this,function(s){switch(s.label){case 0:return[4,this.ensureModelLoaded()];case 1:if(s.sent(),t instanceof e.Tensor)this.checkInputTensorShape(t),n=t,r=t.shape[0];else{if((t=t).length%this.elementsPerExample)throw new Error("The length of the input Float32Array "+t.length+" is not divisible by the number of tensor elements per per example expected by the model "+this.elementsPerExample+".");r=t.length/this.elementsPerExample,n=e.tensor4d(t,[r].concat(this.nonBatchInputShape))}return o=this.model.predict(n),1!==r?[3,3]:(a={},[4,o.data()]);case 2:return[2,(a.scores=s.sent(),a)];case 3:return i=e.unstack(o),l=i.map(function(t){return t.data()}),[4,Promise.all(l)];case 4:return u=s.sent(),e.dispose(i),[2,{scores:u}]}})})},t.prototype.createTransfer=function(t){if(null==this.model)throw new Error("Model has not been loaded yet. Load model by calling ensureModelLoaded(), recognizer(), or startStreaming().");e.util.assert(null!=t&&"string"==typeof t&&t.length>1,"Expected the name for a transfer-learning recognized to be a non-empty string, but got "+JSON.stringify(t)),e.util.assert(null==this.transferRecognizers[t],"There is already a transfer-learning model named '"+t+"'");var r=new c(t,this.parameters,this.model);return this.transferRecognizers[t]=r,r},t.prototype.freezeModel=function(){var t,e;try{for(var r=function(t){var e="function"==typeof Symbol&&t[Symbol.iterator],r=0;return e?e.call(t):{next:function(){return t&&r>=t.length&&(t=void 0),{value:t&&t[r++],done:!t}}}}(this.model.layers),n=r.next();!n.done;n=r.next()){n.value.trainable=!1}}catch(e){t={error:e}}finally{try{n&&!n.done&&(e=r.return)&&e.call(r)}finally{if(t)throw t.error}}},t.prototype.checkInputTensorShape=function(t){var r=this.model.inputs[0].shape.length;if(t.shape.length!==r)throw new Error("Expected input Tensor to have rank "+r+", but got rank "+t.shape.length+" that differs ");var n=t.shape.slice(1),s=this.model.inputs[0].shape.slice(1);if(!e.util.arraysEqual(n,s))throw new Error("Expected input to have shape [null,"+s+"], but got shape [null,"+n+"]")},t.VALID_VOCABULARY_NAMES=["18w","directional4w"],t.DEFAULT_VOCABULARY_NAME="18w",t}(),c=function(t){function o(r,n,s){var o=t.call(this)||this;return o.name=r,o.parameters=n,o.baseModel=s,e.util.assert(null!=r&&"string"==typeof r&&r.length>0,"The name of a transfer model must be a non-empty string, but got "+JSON.stringify(r)),o.nonBatchInputShape=o.baseModel.inputs[0].shape.slice(1),o.words=[],o}return function(t,e){function n(){this.constructor=t}r(t,e),t.prototype=null===e?Object.create(e):(n.prototype=e.prototype,new n)}(o,t),o.prototype.collectExample=function(t){return n(this,void 0,void 0,function(){var r=this;return s(this,function(o){return e.util.assert(!u,"Cannot start collection of transfer-learning example because a streaming recognition or transfer-learning example collection is ongoing"),e.util.assert(null!=t&&"string"==typeof t&&t.length>0,"Must provide a non-empty string when collecting transfer-learning example"),u=!0,[2,new Promise(function(e,o){r.audioDataExtractor=new a({sampleRateHz:r.parameters.sampleRateHz,columnBufferLength:r.parameters.columnBufferLength,columnHopLength:r.parameters.columnBufferLength,numFramesPerSpectrogram:r.nonBatchInputShape[0],columnTruncateLength:r.nonBatchInputShape[1],suppressionTimeMillis:0,spectrogramCallback:function(o){return n(r,void 0,void 0,function(){var r,n;return s(this,function(s){switch(s.label){case 0:return null==this.transferExamples&&(this.transferExamples={}),null==this.transferExamples[t]&&(this.transferExamples[t]=[]),this.transferExamples[t].push(o.clone()),[4,this.audioDataExtractor.stop()];case 1:return s.sent(),u=!1,this.collateTransferWords(),r=e,n={},[4,o.data()];case 2:return r.apply(void 0,[(n.data=s.sent(),n.frameSize=this.nonBatchInputShape[1],n)]),[2,!1]}})})}}),r.audioDataExtractor.start()})]})})},o.prototype.clearExamples=function(){e.util.assert(null!=this.words&&this.words.length>0&&null!=this.transferExamples,"No transfer learning examples exist for model name "+this.name),e.dispose(this.transferExamples),this.transferExamples=null,this.words=null},o.prototype.countExamples=function(){if(null==this.transferExamples)throw new Error("No examples have been collected for transfer-learning model named '"+this.name+"' yet.");var t={};for(var e in this.transferExamples)t[e]=this.transferExamples[e].length;return t},o.prototype.collateTransferWords=function(){this.words=Object.keys(this.transferExamples).sort()},o.prototype.collectTransferDataAsTensors=function(t){var r=this;return e.util.assert(null!=this.words&&this.words.length>0,"No word example is available for tranfer-learning model of name "+t),e.tidy(function(){var t=[],n=[];return r.words.forEach(function(e,s){r.transferExamples[e].forEach(function(e){t.push(e),n.push(s)})}),{xs:e.concat(t,0),ys:e.oneHot(e.tensor1d(n,"int32"),Object.keys(r.words).length)}})},o.prototype.train=function(t){return n(this,void 0,void 0,function(){var r,n,o,a,i,l,u;return s(this,function(s){switch(s.label){case 0:e.util.assert(null!=this.words&&this.words.length>0,"Cannot train transfer-learning model '"+this.name+"' because no transfer learning example has been collected."),e.util.assert(this.words.length>1,"Cannot train transfer-learning model '"+this.name+"' because only 1 word label ('"+JSON.stringify(this.words)+"') has been collected for transfer learning. Requires at least 2."),null==t&&(t={}),null==this.model&&this.createTransferModelFromBaseModel(),r=t.optimizer||"sgd",this.model.compile({loss:"categoricalCrossentropy",optimizer:r,metrics:["acc"]}),n=this.collectTransferDataAsTensors(),o=n.xs,a=n.ys,i=null==t.epochs?20:t.epochs,l=null==t.validationSplit?0:t.validationSplit,s.label=1;case 1:return s.trys.push([1,3,,4]),[4,this.model.fit(o,a,{epochs:i,validationSplit:l,batchSize:t.batchSize,callbacks:null==t.callback?null:[t.callback]})];case 2:return u=s.sent(),e.dispose([o,a]),[2,u];case 3:return s.sent(),e.dispose([o,a]),this.model=null,[2,null];case 4:return[2]}})})},o.prototype.createTransferModelFromBaseModel=function(){e.util.assert(null!=this.words,"No word example is available for tranfer-learning model of name "+this.name);for(var t=this.baseModel.layers,r=t.length-2;r>=0&&"dense"!==t[r].getClassName().toLowerCase();)r--;if(r<0)throw new Error("Cannot find a hidden dense layer in the base model.");var n=t[r].output;this.transferHead=e.sequential(),this.transferHead.add(e.layers.dense({units:this.words.length,activation:"softmax",inputShape:n.shape.slice(1)}));var s=this.transferHead.apply(n);this.model=e.model({inputs:this.baseModel.inputs,outputs:s})},o.prototype.modelInputShape=function(){return this.baseModel.inputs[0].shape},o.prototype.createTransfer=function(t){throw new Error("Creating transfer-learned recognizer from a transfer-learned recognizer is not supported.")},o}(h);t.create=function(t,e){if("BROWSER_FFT"===t)return new h(e);throw"SOFT_FFT"===t?new Error("SOFT_FFT SpeechCommandRecognizer has not been implemented yet."):new Error("Invalid fftType: '"+t+"'")},t.BACKGROUND_NOISE_TAG="_background_noise_",t.UNKNOWN_TAG="_unknown_",t.version=l,Object.defineProperty(t,"__esModule",{value:!0})});
