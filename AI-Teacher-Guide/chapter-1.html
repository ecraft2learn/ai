<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Adding speaking to programs</title>
<link href="/ai/css/ai-teacher-guide.css" rel="stylesheet">
<link href="/ai/css/oer-style.css" rel="stylesheet">
<link rel="icon" type="image/png" href="/ai/images/eCraft2Learn-Favicon.png" />
<script src="/ai/js/ai-guide.js"></script>
</head>
<body>
<script src="/ai/js/translate.js"></script>
<script src="/ai/js/top-of-page.js"></script>
<h3>Chapter 1 - Adding speaking to programs</h3>
<h4>Ken Kahn, University of Oxford</h4>
<h3>Browser compatibility</h3>
<p>This guide includes many interactive elements that currently only run well in the Chrome browser.
This chapter relies upon there being speakers or headphones connected to your computer.
There is a <a href="troubleshooting.html" target="_blank">troubleshooting guide</a>
that should be consulted if problems are encountered.</p>
<h3>Introduction</h3>
<p>The importance of artificial Intelligence in society, the work place, and the economy is rapidly increasing.
It is becoming an important part of many other technologies.
AI conversational agents are becoming common in phones and PCs (Siri, Cortana, OK Google).
Driverless vehicles are coming soon.
Finance, medicine, and many other fields are relying more and more on AI.
Even toys are beginning to embed AI.</p>

<p>Is there something to learn about intelligence in general by studying AI?
AI researchers are attempting to give computers the abilities to perceive, to solve problems, to plan, and to reason.
Perhaps this will shed some light on intelligence beyond what studying human and animal psychology can.</p>

<p>AI raises many questions:</p>
<ul><li>What is the future of work?</li>
<li>How dangerous is AI?</li>
<li>How to ensure AIs make ethical choices?</li>
<li>How might AI help people in medicine, environmental problems, crime prevention, improving agriculture, removing poverty, and more?</li>
<li>Would you want a robot to be your child's best friend?</li></ul>

<h3 class="student-guide">Ways of learning AI</h3>
<h3 class="teacher-guide">Ways of teaching AI</h3>
<p>Broadly there are three approaches</p>
<ol>
<li>Readings, lectures, and discussions about AI's history, ideas, and technologies</li>
<li>Readings, lectures, and discussions about social issues impacted by AI</li>
<li>Supporting hands-on experiences creating AI apps and artefacts</li>
</ol>
<p>While this guide touches on 1 and 2; its focus is on 3.
While some aspects of building AI applications are best suited for those with phds in the field,
there are many projects that even young school students can do.
If the power of speech and image recognition or
the possibilities of machine learning are given easy programming interfaces
then even beginners can use them in their creations.</p>

<h3>Speech synthesis</h3>
<p>Let's start by exploring speech synthesis.
Is the ability to transform text into spoken speech really an example of AI?
Humans need to spend a long time learning to read (out loud).
But reading involves character recognition and comprehension.
When a computer produces speech none of that is involved.
Is generating speech an aspect of intelligent behaviour or it is just like a parrot speaking?
Note that <a href="https://en.wikipedia.org/wiki/Alex_(parrot)" target="_blank">Alex the parrot</a>
clearly did more than "parroting" speech.
Maybe speech synthesis is AI if the program uses AI techniques to generate the output.
The article <a href="https://www.scientificamerican.com/article/new-ai-tech-can-mimic-any-voice/" target="_blank">
<i>New AI Tech Can Mimic Any Voice</i></a> assumes this is AI.
<span class="student-guide">What do you think?</span>
<span class="teacher-guide">Perhaps a good topic for students to discuss.</span>
</p>

<p>Before discussing what is technically involved in synthesising speech
let's look at how it can be used.
Let's start with the simplest program block for speaking.
Click on it to try it out.
(Currently these blocks only work well in Chrome.
Note that the Raspberry Pi has the open source version of Chrome called Chromium and it lacks builtin voices.
The Mary TTS (text-to-speech) blocks below work in any browser.)</p>

<figure>
<div class="iframe-container" style="width: 580px; height: 180px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/simple speak block.xml">
</iframe></div>
<figcaption>A simple block for speaking text. TRY IT</figcaption>
</figure>

<h4>Sentences are more than a series of words</h4>
</p>Speech synthesizers do more than just say each word in a sentence.
They attempt to produce a natural prosody, i.e., the intonation, tone, stress, and rhythm.
They speak questions differently from declarative sentences.
This is very different from <a href="https://www.wired.com/2015/08/stephen-hawking-software-open-source/" target="_blank">
old speech synthesisers such as the one Stephen Hawking uses</a>.
</p>

<figure>
<div  class="iframe-container" style="width: 650px; height: 180px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/separate words.xml"> 
</iframe></div>
<figcaption>An illustration of the difference between speaking one word at a time and whole sentences. TRY IT</figcaption>
</figure>

<p>And for a human speaking numbers and punctuation signs can be a bit challenging.
Is this a sign of intelligence?</p>

<figure>
<div class="iframe-container" style="width: 580px; height: 180px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/numbers signs.xml"> 
</iframe></div>
<figcaption>An illustrations of some issues speaking text containing numbers and signs. TRY IT</figcaption>
</figure>

<p>
<b>Exercise.</b>
Try editing it to see how different numbers are spoken and how it handles special signs.
</p>

<h4>Problems combining speech and sound effects</h4>
<p>Suppose one wanted the computer to speak, be interrupted by a door bell, and then respond accordingly.
Try clicking this and you'll hear there is a problem:</p>

<figure>
<div  class="iframe-container" style="width: 480px; height: 140px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/doorbell problem.xml">
</iframe></div>
<figcaption>An illustration of the problem of making a sequence of utterances and sound effects. TRY IT</figcaption>
</figure>

<p>The problem is that the sound effect begins the same times as the first sentence.
This because the <span class="block-name">Speak</span> block tells the browser to begin speaking and then continues with the next action.
What we want is to have the door bell sound played <i>after</i> the first utterance is finished.
For this we need a slightly more complex block that accepts actions to do after speaking:</p>

<figure>
<div class="iframe-container" style="width: 600px; height: 140px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/doorbell fix.xml">
</iframe></div>
<figcaption>A way to control the timing of utterances and sound effects. TRY IT</figcaption>
</figure>

<p>Being able to express what should happen when speaking finishes is a generally useful ability.
For example, the program may speak some explanation and then do something on the screen.
In many of the examples in the next chapter the programs listen for speech only after the system finishes speaking.</p>

<p>
<b class="student-guide advanced-topic">Click to read an advanced topic</b>
<span>
Code blocks that should run when some computation finishes are an instance of an advanced computer science concept called
<a class="notranslate english" translate=no href="https://en.wikipedia.org/wiki/Continuation" target="_blank">continuations</a>.
These are used to support asynchronous computations.
The complexity introduced by continuations need not make things hard for students.
They can easily place blocks in the <span class="block-name">Speak</span> block without understanding the underlying computer science.
</span></p>

<h4>What is speech synthesis good for?</h4>
<p>Speech synthesis is a good way for software to communicate with people that are blind or visually impaired.
And for devices such as a talking clock or a robot without a display there are few alternatives.
Or when the user's eyes need to attend to something else
(e.g., a surgeon during an operation or a pilot flying a plane).
Speech synthesis is often the best way to communicate with children or adults who have yet to learn to read.
And speech synthesis gives those who physically cannot speak (e.g., Stephen Hawking) a way to communicate.
Many argue that a conversation is often a more natural, friendly, and more pleasant interface to devices
than displays, keyboards, mice, buttons, and touch sensors.</p>

<figure>
<a href="https://www.wired.com/2015/01/intel-gave-stephen-hawking-voice/" target="_blank">
<img src="images/hawking.jpg" class="center">
</a>
<figcaption>Stephen Hawking can communicate thanks to speech synthesis</figcaption></figure>

<h4>Can speech synthesis be misused?</h4>
<p>It is hard to imagine dangers with today's speech synthesis technology.
As it gets better it may enable the automation of tasks that voice actors perform today.
A more serious worry is that the next generation of speech synthesis may be able to
<a href="http://www.radiolab.org/story/breaking-news/" target="_blank">
fool people into thinking that someone said something they didn't</a>.
This is especially worrisome in combination with technology that can alter videos
to change emotional expressions and lip synch.</p>

<b class="student-guide advanced-topic">Click to read an advanced topic</b>
<span>
<h4>How does this work?</h4>
<p>
Modern speech synthesizers (also called "text-to-speech engines" or "TTS engines")
start by preprocessing the text.
Numbers, abbreviations, dates, and special characters are turned into words.
For example, "42" becomes <span class="notranslate english" translate=no>"forty two"</span>
(assuming the language is set to English).
Next words are turned into <a href="https://en.wikipedia.org/wiki/Phoneme" target="_blank">phonemes</a>.
A phoneme is the unit of sound that words are made of.
A phoneme is described phonetically so later stages can pronounce the words.
For example, 
<span
style='font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;
widows: 2;-webkit-text-stroke-width: 0px;text-decoration-style: initial;
text-decoration-color: initial;float:none;word-spacing:0px'>/</span>&#712;f&#601;&#650;ni&#720;m</span><span
style='font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;
widows: 2;-webkit-text-stroke-width: 0px;text-decoration-style: initial;
text-decoration-color: initial;float:none;word-spacing:0px'>/</span></span>
is how the word <span class="notranslate english" translate=no>"phoneme"</span> is pronounced.
This can be done by a dictionary look up or by using pronunciation rules.
Finally sounds are generated as a sequence of pitch and volume changes (typically many thousands per second).
There are three approaches to doing this last step:
<i>concatenative</i> where recorded bits of speech are "glued" together,
<i>formant</i> where each phoneme is synthesized,
and <i>articulatory</i> where human tongues and vocal chords are simulated.
</p>

<p>More details about how speech synthesis works can be found in
the <a href="#additional-resources">Additional resources</a> section at the bottom of this page.</p>
</span>

<h4>Controlling speech synthesis</h4>
<p>A person can speak slow or fast, in a low or high pitch, quietly or loudly, and more.
And different people have different voices and accents.
To mirror these abilities a more complex block is available.
In the following block a parameter value of 1 means the normal pitch, rate, or volume.
Fractional values correspond to low pitch, slow rate, or low volume.
How high the values can be for the opposite effect depends upon the browser and the voice used.
Note that depending upon the voice and browser some of these parameters are ignored.</p>

<figure>
<div class="iframe-container" style="width: 800px; height: 180px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/rate pitch volume.xml">
</iframe></div>
<figcaption>A powerful block for speaking text with many customisation options. TRY IT</figcaption>
</figure>

<p>
<b>Exercise.</b>
A good strategy for trying things out is to vary one thing at a time.
Try changing the rate to a number less than 1 and then greater than 1.
Do the same for the pitch.
Try different voices.
You can see the list of voices available in your browser using the <span class="block-name">Get voice names</span> block.
Some of them are intended to speak other langauges.
</p>

<p>Regarding the 'language' option, unfortunately many browsers currently ignore it.
The argument should be one of the
<a href="https://en.wikipedia.org/wiki/IETF_language_tag" target="_blank">IETF language tags</a>.
It describes the language and dialect, e.g. en-GB.</p>

<p>Fortunately in some browsers (e.g., Chrome) some voices are associated with a language.
When a non-English voice is given English to speak it typically speaks it with an accent.
The selection of voices available depends upon the browser and the operating system.
Click <span class="block-name">get voice names</span> to see the list of voices and
use the voice number in the <span class="block-name">Speak</span> command.
You can also the <span class="block-name">voice that matches</span> to find a voice 
that matches the search terms.
</p>

<figure>
<div class="iframe-container" style="width: 800px; height: 600px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/voices.xml"> 
</iframe></div>
<figcaption>A demonstration of different speaking voices (and languages). TRY IT</figcaption>
</figure>

<p>A voice is more than just a voice.
Listen to the two ways of reading dates.</p>

<figure>
<div class="iframe-container" style="width: 800px; height: 500px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/dates.xml"> 
</iframe></div>
<figcaption>Different voices speak dates differently depending upon whether they are speaking US or UK English. TRY IT</figcaption>
</figure>

<h4>If your browser has too few available voices or you want to try a different speech engine</h4>
<p>Some browsers and some operating systems have very few (or <i>no</i>) voices.
An alternative speech block uses <a href="http://mary.dfki.de/" target="_blank">a server in Germany</a> that has its own set of voices.</p>

<figure>
<div class="iframe-container" style="width: 800px; height: 500px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/Mary voices.xml"> 
</iframe></div>
<figcaption>An alternative text-to-speech engine. TRY IT</figcaption>
</figure>

<h4>Heteronyms cause problems</h4>
<p><a href="https://en.wikipedia.org/wiki/Heteronym_(linguistics)" target="_blank">Heteronyms</a> are words that mean and sound different but are spelled the same.
The English word <span class="notranslate english" translate=no>"Read"</span>
can sound like <span class="notranslate english" translate=no>"reed"</span> or
<span class="notranslate english" translate=no>"red"</span> depending upon the tense.
The English word <span class="notranslate english" translate=no>"Lead"</span> the verb
sounds different from <span class="notranslate english" translate=no>"lead"</span> the metal.
Some voices are better than others at using the correct pronunciation.
Explore how different voices deal with <span class="notranslate english" translate=no>"read"</span> in the following.
Try editing the sentences to see how they deal with <span class="notranslate english" translate=no>"lead"</span> and other words.
Try this in another language.</p>

<figure>
<div class="iframe-container" style="width: 800px; height: 500px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="/ai/snap/snap.html"
        project_path="/ai/AI-teacher-guide-projects/read problem.xml"> 
</iframe></div>
<figcaption>An example of the problem of speaking words such as <span class="notranslate english" translate=no>'read'</span>. TRY IT</figcaption>
</figure>

<p>
<b>Exercise.</b>
Can you think of any other words that are pronounced in more than one way?
See if the voices can figure out the right one from the surrounding words.
</p>

<h4>Two sample programs using speech synthesis</h4>
<p>This <a href="https://snap.berkeley.edu/snapsource/snap.html#present:Username=toontalk&ProjectName=speak%20randomly" target="_blank">
sample speech synthesis program</a> uses random settings for rate, pitch, and voice.
When one clicks on the picture of some numbers a random number is spoken with a random voices
(and hence a random language) as well as a random pitch and rate.
Numbers are well-suited for this since numbers are spoken in the language of the voice.
The parrot repeats what it hears
(see <a class="guide-link" href="chapter-2.html">the next chapter</a>).
Hearing your utterances repeated in a strange voice with a random pitch and rate can be entertaining.
As can hearing your speech repeated in a foreign accent.
As with all sample programs the blocks implementing it can be easily found.
Click on <img src="images/show-blocks.png"> to see the blocks behind a program.
If you click on the <span "block-name">Parrot</span> or <span "block-name">Numbers</span>
sprite in the lower right you will see these sample programs.</p>

<h4 id="project-ideas">Possible project ideas using speech synthesis</h4>
<p>Here are some ideas for projects using only speech synthesis, see
<a class="guide-link" href="chapter-2.html">the next chapter</a>
for ideas combining speech synthesis and recognition.
<ul>
<li>Have sprites put on a play where each sprite speaks with a different voice.</li>
<li>Have a robot talk out loud as it moves around. E.g. "whoops" when it collides with something, or "time to turn" before it turns.</li>
<li>Make a page reader that speaks the contents of a file on the web.</li>
<li>Enhance a program to speak as it runs to produce explanations or help in debugging.</li>
<li>Make a talking clock or calculator.</li>
<li>Make a spelling game where words to be spelled are spoken.</li>
<li class="teacher-guide">There are thousands more ways students could use speech synthesis in their projects.</li>
<li class="student-guide">Be creative. Think of something and try to build it.</li>
</ul>
</p>

<h4>Is there even more to speech synthesis?</h4>
<p>There are many more possibilities to control speech.
A voice can sound like a robot, like whispering, like a crowd in a stadium or a chorus.
You can experiment with these kinds of speech effects at
<a href="http://mary.dfki.de:59125/" target="_blank">the MARY TTS (text-to-speech) site</a>
by clicking on the 'Show Audio Effects' button.</p>

<p>Speech can be emotional; the speaker can sound angry, happy, sad, and so on.
One way to experiment with this is to change the input type from
<span "block-name">TEXT</span> to <span "block-name">EMOTIONML</span>
at <a href="http://mary.dfki.de:59125/" target="_blank">the MARY TTS site</a>.
There is a standard called
<a class="notranslate" translate=no href="https://www.w3.org/TR/speech-synthesis/" target="_blank">Speech Synthesis Markup Language</a>
that provides great control over how the speech is generated.
However, it has yet to be implemented in the voices one commonly finds available in browsers.</p>

<p>Listen to these samples of
<a href="https://google.github.io/tacotron/publications/tacotron2/index.html" target="_blank">
generated speech from the latest research from Google</a>.</p>

<p>A very impressive use of controlled speech is the <a href="https://experiments.withgoogle.com/ai/giorgio-cam" target="_blank">Giorgio Cam</a>
experiment by Google researchers.
It combines computer vision and controlled speech to rap about what is in front of a webcam.</p>

<h3 id="additional-resources">Additional resources</h3>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition" target="_blank">
A complete description of the speech synthesis API</a>
that web browsers support.</p>

<p><a href="http://research.spa.aalto.fi/publications/theses/lemmetty_mst/chap2.html" target="_blank">
A history of speech synthesis</a>.</p>

<p><a href="http://www.explainthatstuff.com/how-speech-synthesis-works.html" target="_blank">
A long explanation of how speech synthesis is done</a> by <i class="notranslate english" translate=no>Explain that Stuff</i>.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Speech_synthesis" target="_blank">Wikipedia entry</a> is good.</p>

<h4>Suggestions for using this guide</h4>
<p>An excellent way to learn about new programming constructs such as the blocks in this guide is to
<i>tinker</i> with them.
Explore what each block can and can't do.
See what effects the parameters have.
Then try them out in your own projects perhaps starting with the simple blocks.
</p>

<script src="/ai/js/where-to-get-library.js"></script>

<h3>Learn about speech recognition</h3>
Go to
<a class="guide-link" href="chapter-2.html">the next chapter on speech recognition</a>

<script src="/ai/js/bottom-of-page.js"></script>
</body></html>