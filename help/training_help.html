<html>
<head>
<link href="../css/ai-teacher-guide.css" rel="stylesheet">
<style>
p {
  border-radius: 0px;
  padding: 0px;
}
</style>
<title>How to control the training of your model</title>
</head>
<body style="margin: 0;
             padding-left: 0px;
             max-width: 800px;">
<p>
You can control several things about how your model will learn.
You can set the number of iterations the training algorithm will take.
Each iteration the program adjusts the weights of the neurons to reduce the loss.
You can see the best number of iterations from the graph by selecting the point where it starts to level off.
</p>
<p>
You can choose the learning rate which determines how much progress it can make on each training iteration.
The learning rate determines how much it changes the weights of the neurons to reduce the "loss".
Larger learning rates makes the training faster
but may cause the error to increase by taking such a big step that passes over the optimal values.
You can decide whether the data is shuffled on each step to eliminate the possibility that the model
will be trained for input in a particular order.
</p>
<p>
Recall that the purpose of training is to reduce the loss.
Loss is a measure of the distance between the values the model predicts for training set inputs
and training set output values.
Many of the optimization methods used in training adjust internal parameters to improve the speed and accuracy of the training.
However if they do this by relying upon only the training data they may learning neuron weights that work well
only for the training data and not real or test data.
This problem is called "overfitting" because the model fits only the training data well.
To remedy this you can set the "validation split" so that some of the training data is used only for 
adjusting the learning parameters.
You can also load saved training data as a validation dataset.
When validation data is available the training graphs will display
loss and accuracy for both the training and the validation data (labelled 'val_loss' and 'val_acc').
Accuracy is a measure of how often the model gave the correct answer.
If the validation loss starts increasing (or validation accuracy decreasing)
while your training loss is still decreasing (or training accuracy increasing),
this is an indicator of overfitting.
Read this <a href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" target="_blank">
article about training, validation, and test data</a> to learn more.
</p>
</body>
</html>