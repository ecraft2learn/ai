<!doctype html>
<html>
<head>
<script src="/ai/js/load-scripts.js"></script>
<script>
load_local_or_remote_scripts(
    ["../js/tfjs.js",
     "../js/tfjs-vis.js",
     "../js/dat.gui.js"],
    ["https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest",
     "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis",
     "https://cdn.jsdelivr.net/npm/dat.gui"]);
</script>
<script src="../tensorflow/tensorflow.js"></script>
<link href="/ai/css/ai-teacher-guide.css" rel="stylesheet">
<link href="/uui/help/oer-style.css" rel="stylesheet">
<title>Training a model to win Tic Tac Toe games</title>
</head>
<body style="margin: 0;
             max-width: 800px;">
<h2>
Experiment with how to train a neural net to win at Tic Tac Toe
</h2>
<h3 id="settings" style="display:none">Settings</h3>
<h3>Tutorial</h3>
<p>
To train the computer to play Tic Tac Toe we'll need to generate records of game play.
The simplest way to start is for the computer to simulate both players making random (legal) moves.
For every board position it records whether it eventually led to a win for X, O, or a tie.
The trained model on each turn will then consider all possible moves and consider their relative scores.
You can choose whether the trained computer player just picks the highest scoring move 
or uses the scores as probabilities of making that move.
</p>
<p>
Let's start by having the computer play games where both players just make random moves.
You can choose how many games it will play in the settings panel that will appear at the top of this page.
</p>
<button id="create_data" class="support-window-button" >Create initial data</button>
<p>
Now let's define how the computer will learn.
The loss is a measure of the distance between the values the model predicts and the known correct values.
You can choose among several
<a href="https://medium.com/@risingdeveloper/visualization-of-some-loss-functions-for-deep-learning-with-tensorflow-9f60be9d09f9" target="_blank">
loss functions</a> for computing this distance.
</p>
<p>
You can also decide on the size of the layers of the neural net.
The default numbers are 100, 50, 20, and 1.
This means that that each of the nine inputs corresponding to the nine board positions are connected to 100 neurons.
Each of those 100 neurons are then connected to a layer with 50 units which is connected to one with 20.
Those 20 neurons are then combined to a single number which is the "score" for a board.
Currently the only kind of connection between layers is "dense"
which means each neuron of a layer is connected to each neuron of the next layer.
More and wider layers up to a point should make the model more accurate but also slower
and at some point may require too much memory (in the GPU).
</p>
<button disabled id="create_model" class="support-window-button">Create a model</button>
<p>
Now let's train the computer using the games you just generated.
You can set the number of iterations the training algorithm will take.
Each iteration the program adjusts the weights of the neurons to reduce the loss.
You can see the best number of iterations from the graph by selecting the point where it starts to level off.
</p>
<p>
You can choose the learning rate which determines how much progress it can make on each training iteration.
The learning rate determines how much it changes the weights of the neurons to reduce the "loss".
Larger learning rates makes the training faster
but may cause the error to increase by taking such a big step that passes over the optimal values.
You can decide whether the data is shuffled on each step to eliminate the possibility that the model
will be trained for input in a particular order.
</p>
<p>
Recall that the purpose of training is to reduce the loss.
Loss is a measure of the distance between the values the model predicts for training set inputs
and training set output values.
Many of the optimization methods used in training adjust internal parameters to improve the speed and accuracy of the training.
However if they do this by relying upon only the training data they may learning neuron weights that work well
only for the training data and not real or test data.
This problem is called "overfitting" because the model fits only the training data well.
To remedy this you can set the "validation split" so that some of the training data is used only for 
adjusting the learning parameters.
You can also load saved training data as a validation dataset.
When validation data is available the training graphs will display
loss and accuracy for both the training and the validation data (labeled 'val_loss' and 'val_acc').
Accuracy is a measure of how often the model gave the correct answer.
If the validation loss starts increasing (or validation accuracy decreasing)
while your training loss is still decreasing (or training accuracy increasing),
this is an indicator of overfitting.
Read this <a href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" target="_blank">
article about training, validation, and test data</a> to learn more.
</p>
<button disabled id="train" class="support-window-button">Train the model</button>
<p>
How good is the computer at playing Tic Tac Toe now that you've trained it?
One test is how well does it score the first move for X.
The center and corners should score higher than the others.
</p>
<p>
Another way to evaluate the training is to have it play lots of games (you can decide how many in the Settings panel).
You can have the trained model play against itself or against a player that makes random moves.
If the player using the trained model always picks the highest scoring move then every game will be the same.
Another strategy is to use the scores to determine the probability of making that move.
High scoring moves are more likely than others but all moves can occur.
If no moves have a positive score then all are considered likely to lead to a loss.
In this case the least negative choice is selected.
</p>
<button disabled id="evaluate" class="support-window-button" >Evaluate the training</button>
<p>
You can save a trained model to the local file system to load at a later time.
</p>
<button id="save_and_load" class="support-window-button" >Saving and loading</button>
<h3>Things to try</h3>
<p>
Try different layer sizes for the model.
Larger ones may lead to more accuracy at a cost of speed and memory usage.
The learning rate is also worth exploring.
One approach is to split the training up where each subsequent training session has a significantly smaller learning rate.
Also set the number of iterations so that the learning is just levelling off so no need to waste time with more training.
</p>
<p>
In addition to experimenting with different parameter settings,
one can use games played by trained players to do further training.
The default settings is that games created during the evaluation phase are added
to the dataset of games available during training.
</p>
<script src="./tic-tac-toe.js"> </script>
<script src="/ai/js/bottom-of-page.js"></script>
</body>
</html>